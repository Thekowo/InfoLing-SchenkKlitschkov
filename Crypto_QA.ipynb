{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "source": [],
        "metadata": {
          "collapsed": false
        }
      }
    },
    "colab": {
      "name": "Crypto QA.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Thekowo/InfoLing-SchenkKlitschkov/blob/main/Crypto_QA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "2_L_BZIF7CUH"
      },
      "source": [
        "### Prepare environment\n",
        "\n",
        "#### Colab: Enable the GPU runtime\n",
        "GPU runtime should be enabled for optimal speed.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/deepset-ai/haystack/master/docs/_src/img/colab_gpu_runtime.jpg\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "0Xk7IWr-7CUI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5001292-a004-4e2d-8182-0db10fe32db9"
      },
      "source": [
        "# Make sure you have a GPU running\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun Jul 11 19:31:30 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.42.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   48C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcaJc4-87CUI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "284b792a-6cd2-4ca7-c1eb-f2497645540a"
      },
      "source": [
        "# Install the latest release of Haystack in your own environment \n",
        "#! pip install farm-haystack\n",
        "\n",
        "# Install the latest master of Haystack\n",
        "!pip install grpcio-tools==1.34.1\n",
        "!pip install git+https://github.com/deepset-ai/haystack.git\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting grpcio-tools==1.34.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ef/b8/086bc32788e7127f6655c1ec3bd000902e4c9225b587b19b09c4d8ced384/grpcio_tools-1.34.1-cp37-cp37m-manylinux2014_x86_64.whl (2.5MB)\n",
            "\u001b[K     |████████████████████████████████| 2.5MB 8.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.34.1 in /usr/local/lib/python3.7/dist-packages (from grpcio-tools==1.34.1) (1.34.1)\n",
            "Requirement already satisfied: protobuf<4.0dev,>=3.5.0.post1 in /usr/local/lib/python3.7/dist-packages (from grpcio-tools==1.34.1) (3.17.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from grpcio-tools==1.34.1) (57.0.0)\n",
            "Requirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.7/dist-packages (from grpcio>=1.34.1->grpcio-tools==1.34.1) (1.15.0)\n",
            "Installing collected packages: grpcio-tools\n",
            "Successfully installed grpcio-tools-1.34.1\n",
            "Collecting git+https://github.com/deepset-ai/haystack.git\n",
            "  Cloning https://github.com/deepset-ai/haystack.git to /tmp/pip-req-build-qfssiuti\n",
            "  Running command git clone -q https://github.com/deepset-ai/haystack.git /tmp/pip-req-build-qfssiuti\n",
            "Collecting farm==0.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/70/c8/716e698e506b11df347529162890e29f4e1d71e90c09d1047748c8b6e77d/farm-0.8.0-py3-none-any.whl (204kB)\n",
            "\u001b[K     |████████████████████████████████| 215kB 6.7MB/s \n",
            "\u001b[?25hCollecting fastapi\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f8/cb/2682d18ac7a553a0203f48190f474ab6dde6cd8815ac6822a46d611e6661/fastapi-0.66.0-py3-none-any.whl (51kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 7.8MB/s \n",
            "\u001b[?25hCollecting uvicorn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bf/fe/a41994c92897b162c0c83e8ef10bec54ebdefbce3f3725b530d2091492ac/uvicorn-0.14.0-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.1MB/s \n",
            "\u001b[?25hCollecting gunicorn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e4/dd/5b190393e6066286773a67dfcc2f9492058e9b57c4867a95f1ba5caf0a83/gunicorn-20.1.0-py3-none-any.whl (79kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 7.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from farm-haystack==0.9.0) (1.1.5)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (from farm-haystack==0.9.0) (0.0)\n",
            "Collecting elasticsearch<=7.10,>=7.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/ba/f950bdd9164fb2bbbe5093700162234fbe61f446fe2300a8993761c132ca/elasticsearch-7.10.0-py2.py3-none-any.whl (321kB)\n",
            "\u001b[K     |████████████████████████████████| 327kB 10.9MB/s \n",
            "\u001b[?25hCollecting elastic-apm\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c0/89/28305b9dc024a44e2a7b824316a5f2e874200b534b8b2fef47f8f6fe241b/elastic_apm-6.3.2-cp37-cp37m-manylinux2010_x86_64.whl (330kB)\n",
            "\u001b[K     |████████████████████████████████| 337kB 13.3MB/s \n",
            "\u001b[?25hCollecting tox\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d8/63/2fa635ac1b8a22e960654b07c270dfb53eb873aba261006536de40327b18/tox-3.23.1-py2.py3-none-any.whl (85kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 10.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: coverage in /usr/local/lib/python3.7/dist-packages (from farm-haystack==0.9.0) (3.7.1)\n",
            "Collecting langdetect\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0e/72/a3add0e4eec4eb9e2569554f7c70f4a3c27712f40e3284d483e88094cc0e/langdetect-1.0.9.tar.gz (981kB)\n",
            "\u001b[K     |████████████████████████████████| 983kB 15.9MB/s \n",
            "\u001b[?25hCollecting python-multipart\n",
            "  Downloading https://files.pythonhosted.org/packages/46/40/a933ac570bf7aad12a298fc53458115cc74053474a72fbb8201d7dc06d3d/python-multipart-0.0.5.tar.gz\n",
            "Collecting python-docx\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8b/a0/52729ce4aa026f31b74cc877be1d11e4ddeaa361dc7aebec148171644b33/python-docx-0.8.11.tar.gz (5.6MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6MB 29.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.7/dist-packages (from farm-haystack==0.9.0) (1.4.20)\n",
            "Collecting sqlalchemy_utils\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/84/ab/5fe020d74081e7416f6e53384f682976e81b8f105fa0e74b854810ed4a94/SQLAlchemy_Utils-0.37.8-py3-none-any.whl (100kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 14.7MB/s \n",
            "\u001b[?25hCollecting faiss-cpu>=1.6.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/d6/072a9d18430b8c68c99ffb49fe14fbf89c62f71dcd4f5f692c7691447a14/faiss_cpu-1.7.1.post2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.4MB)\n",
            "\u001b[K     |████████████████████████████████| 8.4MB 21.9MB/s \n",
            "\u001b[?25hCollecting tika\n",
            "  Downloading https://files.pythonhosted.org/packages/96/07/244fbb9c74c0de8a3745cc9f3f496077a29f6418c7cbd90d68fd799574cb/tika-1.24.tar.gz\n",
            "Collecting httptools\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/87/ebb92639705924aac5ed6aa91bd4332b20d7180f3e94bd168742e7671025/httptools-0.2.0-cp37-cp37m-manylinux1_x86_64.whl (344kB)\n",
            "\u001b[K     |████████████████████████████████| 348kB 43.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from farm-haystack==0.9.0) (3.2.5)\n",
            "Requirement already satisfied: more_itertools in /usr/local/lib/python3.7/dist-packages (from farm-haystack==0.9.0) (8.8.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from farm-haystack==0.9.0) (2.5.1)\n",
            "Collecting pymilvus\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9d/eb/1464c32113b6de44101dac58d1beb95c9ce4898139c8b69521135d431e19/pymilvus-1.1.2-py3-none-any.whl (56kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 10.8MB/s \n",
            "\u001b[?25hCollecting SPARQLWrapper\n",
            "  Downloading https://files.pythonhosted.org/packages/00/9b/443fbe06996c080ee9c1f01b04e2f683b2b07e149905f33a2397ee3b80a2/SPARQLWrapper-1.8.5-py3-none-any.whl\n",
            "Collecting mmh3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d9/46/0e568554c7f70ebc3de0c2b2effd3f7b25e66e0e4e0eacaeb7c9145949f2/mmh3-3.0.0-cp37-cp37m-manylinux2010_x86_64.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 8.7MB/s \n",
            "\u001b[?25hCollecting weaviate-client\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4d/26/68aa4a2a797776785bc348e13dc91fed4fadbde2e88b09c9620567191838/weaviate_client-2.5.0-py3-none-any.whl (56kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 9.8MB/s \n",
            "\u001b[?25hCollecting psycopg2-binary\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5b/62/5f8eae172230141a53305150637fbdda7a535618d5dfa976dc013396837f/psycopg2_binary-2.9.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4MB)\n",
            "\u001b[K     |████████████████████████████████| 3.4MB 47.8MB/s \n",
            "\u001b[?25hCollecting uvloop==0.14\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/7a/54a80c03b555af21680a2f3692947b43a0d576d90c4c18cace0fee1ccc0e/uvloop-0.14.0-cp37-cp37m-manylinux2010_x86_64.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 40.5MB/s \n",
            "\u001b[?25hCollecting flask-cors\n",
            "  Downloading https://files.pythonhosted.org/packages/db/84/901e700de86604b1c4ef4b57110d4e947c218b9997adf5d38fa7da493bce/Flask_Cors-3.0.10-py2.py3-none-any.whl\n",
            "Collecting boto3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7a/65/c5fa632ca1c243d0f757c09cc4656f361dc1a9555f0b6d442e374f7ca8f6/boto3-1.17.109-py2.py3-none-any.whl (131kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 58.0MB/s \n",
            "\u001b[?25hCollecting Werkzeug==0.16.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c2/e4/a859d2fe516f466642fa5c6054fd9646271f9da26b0cac0d2f37fc858c8f/Werkzeug-0.16.1-py2.py3-none-any.whl (327kB)\n",
            "\u001b[K     |████████████████████████████████| 327kB 52.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: flask in /usr/local/lib/python3.7/dist-packages (from farm==0.8.0->farm-haystack==0.9.0) (1.1.4)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.7/dist-packages (from farm==0.8.0->farm-haystack==0.9.0) (1.4.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from farm==0.8.0->farm-haystack==0.9.0) (4.41.1)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from farm==0.8.0->farm-haystack==0.9.0) (0.3.4)\n",
            "Collecting mlflow<=1.13.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/4d/a6a4460e214842377dbc43d3e83bf976d564f7976822a9351adde60af44b/mlflow-1.13.1-py3-none-any.whl (14.1MB)\n",
            "\u001b[K     |████████████████████████████████| 14.2MB 223kB/s \n",
            "\u001b[?25hCollecting flask-restplus\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c2/a6/b17c848771f96ad039ad9e3ea275e842a16c39c4f3eb9f60ee330b20b6c2/flask_restplus-0.13.0-py2.py3-none-any.whl (2.5MB)\n",
            "\u001b[K     |████████████████████████████████| 2.5MB 41.8MB/s \n",
            "\u001b[?25hCollecting seqeval\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9d/2d/233c79d5b4e5ab1dbf111242299153f3caddddbb691219f363ad55ce783d/seqeval-1.2.2.tar.gz (43kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 9.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from farm==0.8.0->farm-haystack==0.9.0) (57.0.0)\n",
            "Collecting torch<1.9,>1.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/56/74/6fc9dee50f7c93d6b7d9644554bdc9692f3023fa5d1de779666e6bf8ae76/torch-1.8.1-cp37-cp37m-manylinux1_x86_64.whl (804.1MB)\n",
            "\u001b[K     |████████████████████████████████| 804.1MB 19kB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from farm==0.8.0->farm-haystack==0.9.0) (0.36.2)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ac/aa/1437691b0c7c83086ebb79ce2da16e00bef024f24fec2a5161c35476f499/sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 96kB/s \n",
            "\u001b[?25hCollecting transformers==4.6.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d5/43/cfe4ee779bbd6a678ac6a97c5a5cdeb03c35f9eaebbb9720b036680f9a2d/transformers-4.6.1-py3-none-any.whl (2.2MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3MB 39.0MB/s \n",
            "\u001b[?25hCollecting dotmap\n",
            "  Downloading https://files.pythonhosted.org/packages/17/6f/c94adbb0e6d418ededbf1082a3067f178fb012573b960d446e5655e6fbe1/dotmap-1.3.23-py3-none-any.whl\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from farm==0.8.0->farm-haystack==0.9.0) (2.23.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from farm==0.8.0->farm-haystack==0.9.0) (5.4.8)\n",
            "Collecting starlette==0.14.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/15/34/db1890f442a1cd3a2c761f4109a0eb4e63503218d70a8c8e97faa09a5500/starlette-0.14.2-py3-none-any.whl (60kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 9.4MB/s \n",
            "\u001b[?25hCollecting pydantic!=1.7,!=1.7.1,!=1.7.2,!=1.7.3,!=1.8,!=1.8.1,<2.0.0,>=1.6.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9f/f2/2d5425efe57f6c4e06cbe5e587c1fd16929dcf0eb90bd4d3d1e1c97d1151/pydantic-1.8.2-cp37-cp37m-manylinux2014_x86_64.whl (10.1MB)\n",
            "\u001b[K     |████████████████████████████████| 10.1MB 28.7MB/s \n",
            "\u001b[?25hCollecting h11>=0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/0f/7a0eeea938eaf61074f29fed9717f2010e8d0e0905d36b38d3275a1e4622/h11-0.12.0-py3-none-any.whl (54kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 8.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: click>=7.* in /usr/local/lib/python3.7/dist-packages (from uvicorn->farm-haystack==0.9.0) (7.1.2)\n",
            "Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from uvicorn->farm-haystack==0.9.0) (3.7.4.3)\n",
            "Collecting asgiref>=3.3.4\n",
            "  Downloading https://files.pythonhosted.org/packages/fe/66/577f32b54c50dcd8dec38447258e82ed327ecb86820d67ae7b3dea784f13/asgiref-3.4.1-py3-none-any.whl\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas->farm-haystack==0.9.0) (1.19.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->farm-haystack==0.9.0) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->farm-haystack==0.9.0) (2018.9)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn->farm-haystack==0.9.0) (0.22.2.post1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from elasticsearch<=7.10,>=7.7->farm-haystack==0.9.0) (2021.5.30)\n",
            "Requirement already satisfied: urllib3<2,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from elasticsearch<=7.10,>=7.7->farm-haystack==0.9.0) (1.24.3)\n",
            "Requirement already satisfied: toml>=0.9.4 in /usr/local/lib/python3.7/dist-packages (from tox->farm-haystack==0.9.0) (0.10.2)\n",
            "Collecting virtualenv!=20.0.0,!=20.0.1,!=20.0.2,!=20.0.3,!=20.0.4,!=20.0.5,!=20.0.6,!=20.0.7,>=16.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/03/08/f819421002e85a71d58368f7bffbe0b1921325e0e8ca7857cb5fb0e1f7c1/virtualenv-20.4.7-py2.py3-none-any.whl (7.2MB)\n",
            "\u001b[K     |████████████████████████████████| 7.2MB 23.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=14 in /usr/local/lib/python3.7/dist-packages (from tox->farm-haystack==0.9.0) (20.9)\n",
            "Requirement already satisfied: importlib-metadata>=0.12; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from tox->farm-haystack==0.9.0) (4.6.0)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from tox->farm-haystack==0.9.0) (1.15.0)\n",
            "Requirement already satisfied: py>=1.4.17 in /usr/local/lib/python3.7/dist-packages (from tox->farm-haystack==0.9.0) (1.10.0)\n",
            "Requirement already satisfied: filelock>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from tox->farm-haystack==0.9.0) (3.0.12)\n",
            "Collecting pluggy>=0.12.0\n",
            "  Downloading https://files.pythonhosted.org/packages/a0/28/85c7aa31b80d150b772fbe4a229487bc6644da9ccb7e427dd8cc60cb8a62/pluggy-0.13.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: lxml>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from python-docx->farm-haystack==0.9.0) (4.2.6)\n",
            "Requirement already satisfied: greenlet!=0.4.17; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.4.2->farm-haystack==0.9.0) (1.1.0)\n",
            "Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx->farm-haystack==0.9.0) (4.4.2)\n",
            "Collecting ujson>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/17/4e/50e8e4cf5f00b537095711c2c86ac4d7191aed2b4fffd5a19f06898f6929/ujson-4.0.2-cp37-cp37m-manylinux1_x86_64.whl (179kB)\n",
            "\u001b[K     |████████████████████████████████| 184kB 58.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio-tools<1.38.0,>=1.22.0 in /usr/local/lib/python3.7/dist-packages (from pymilvus->farm-haystack==0.9.0) (1.34.1)\n",
            "Requirement already satisfied: grpcio<1.38.0,>=1.22.0 in /usr/local/lib/python3.7/dist-packages (from pymilvus->farm-haystack==0.9.0) (1.34.1)\n",
            "Collecting rdflib>=4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/6b/6454aa1db753c0f8bc265a5bd5c10b5721a4bb24160fb4faf758cf6be8a1/rdflib-5.0.0-py3-none-any.whl (231kB)\n",
            "\u001b[K     |████████████████████████████████| 235kB 59.4MB/s \n",
            "\u001b[?25hCollecting validators>=0.18.2\n",
            "  Downloading https://files.pythonhosted.org/packages/db/2f/7fed3ee94ad665ad2c1de87f858f10a7785251ff75b4fd47987888d07ef1/validators-0.18.2-py3-none-any.whl\n",
            "Collecting s3transfer<0.5.0,>=0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/63/d0/693477c688348654ddc21dcdce0817653a294aa43f41771084c25e7ff9c7/s3transfer-0.4.2-py2.py3-none-any.whl (79kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 12.1MB/s \n",
            "\u001b[?25hCollecting botocore<1.21.0,>=1.20.109\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/53/779ef784d896647f53e629143b5002adee52ea4574aa3dfaa8a9fe322c92/botocore-1.20.109-py2.py3-none-any.whl (7.7MB)\n",
            "\u001b[K     |████████████████████████████████| 7.7MB 43.2MB/s \n",
            "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from flask->farm==0.8.0->farm-haystack==0.9.0) (2.11.3)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from flask->farm==0.8.0->farm-haystack==0.9.0) (1.1.0)\n",
            "Collecting alembic<=1.4.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e0/e9/359dbb77c35c419df0aedeb1d53e71e7e3f438ff64a8fdb048c907404de3/alembic-1.4.1.tar.gz (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 52.6MB/s \n",
            "\u001b[?25hCollecting prometheus-flask-exporter\n",
            "  Downloading https://files.pythonhosted.org/packages/f3/c1/2cc385fadf18dc75fe24c18899269eda4dcc60221d61eff7da4a6cc5c01d/prometheus_flask_exporter-0.18.2.tar.gz\n",
            "Collecting azure-storage-blob>=12.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/01/e5/ff9609a85f71cd41d759307b9d385ace34d29378e4750d0a0240aad535cb/azure_storage_blob-12.8.1-py2.py3-none-any.whl (345kB)\n",
            "\u001b[K     |████████████████████████████████| 348kB 45.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from mlflow<=1.13.1->farm==0.8.0->farm-haystack==0.9.0) (1.3.0)\n",
            "Collecting gitpython>=2.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/91/b38c4fabb6e5092ab23492ded4f318ab7299b19263272b703478038c0fbc/GitPython-3.1.18-py3-none-any.whl (170kB)\n",
            "\u001b[K     |████████████████████████████████| 174kB 58.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from mlflow<=1.13.1->farm==0.8.0->farm-haystack==0.9.0) (3.17.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from mlflow<=1.13.1->farm==0.8.0->farm-haystack==0.9.0) (3.13)\n",
            "Collecting databricks-cli>=0.8.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/af/631375abc29e59cedfa4467a5f7755503ba19898890751e1f2636ef02f92/databricks-cli-0.14.3.tar.gz (54kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 10.3MB/s \n",
            "\u001b[?25hCollecting docker>=4.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b2/5a/f988909dfed18c1ac42ad8d9e611e6c5657e270aa6eb68559985dbb69c13/docker-5.0.0-py2.py3-none-any.whl (146kB)\n",
            "\u001b[K     |████████████████████████████████| 153kB 45.2MB/s \n",
            "\u001b[?25hCollecting querystring-parser\n",
            "  Downloading https://files.pythonhosted.org/packages/88/6b/572b2590fd55114118bf08bde63c0a421dcc82d593700f3e2ad89908a8a9/querystring_parser-1.2.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: sqlparse>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from mlflow<=1.13.1->farm==0.8.0->farm-haystack==0.9.0) (0.4.1)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.7/dist-packages (from mlflow<=1.13.1->farm==0.8.0->farm-haystack==0.9.0) (0.3)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from flask-restplus->farm==0.8.0->farm-haystack==0.9.0) (2.6.0)\n",
            "Collecting aniso8601>=0.82\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/04/e97c12dc034791d7b504860acfcdd2963fa21ae61eaca1c9d31245f812c3/aniso8601-9.0.1-py2.py3-none-any.whl (52kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 9.8MB/s \n",
            "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/e2/df3543e8ffdab68f5acc73f613de9c2b155ac47f162e725dcac87c521c11/tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 46.2MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 55.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.6.1->farm==0.8.0->farm-haystack==0.9.0) (2019.12.20)\n",
            "Collecting huggingface-hub==0.0.8\n",
            "  Downloading https://files.pythonhosted.org/packages/a1/88/7b1e45720ecf59c6c6737ff332f41c955963090a18e72acbcbeac6b25e86/huggingface_hub-0.0.8-py3-none-any.whl\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->farm==0.8.0->farm-haystack==0.9.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->farm==0.8.0->farm-haystack==0.9.0) (3.0.4)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn->farm-haystack==0.9.0) (1.0.1)\n",
            "Requirement already satisfied: appdirs<2,>=1.4.3 in /usr/local/lib/python3.7/dist-packages (from virtualenv!=20.0.0,!=20.0.1,!=20.0.2,!=20.0.3,!=20.0.4,!=20.0.5,!=20.0.6,!=20.0.7,>=16.0.0->tox->farm-haystack==0.9.0) (1.4.4)\n",
            "Collecting distlib<1,>=0.3.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/26/f6a23dd3e578132cf924e0dd5d4e055af0cd4ab43e2a9f10b7568bfb39d9/distlib-0.3.2-py2.py3-none-any.whl (338kB)\n",
            "\u001b[K     |████████████████████████████████| 348kB 58.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14->tox->farm-haystack==0.9.0) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.12; python_version < \"3.8\"->tox->farm-haystack==0.9.0) (3.4.1)\n",
            "Collecting isodate\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/9f/b36f7774ff5ea8e428fdcfc4bb332c39ee5b9362ddd3d40d9516a55221b2/isodate-0.6.0-py2.py3-none-any.whl (45kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 8.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->flask->farm==0.8.0->farm-haystack==0.9.0) (2.0.1)\n",
            "Collecting Mako\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f3/54/dbc07fbb20865d3b78fdb7cf7fa713e2cba4f87f71100074ef2dc9f9d1f7/Mako-1.1.4-py2.py3-none-any.whl (75kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 12.2MB/s \n",
            "\u001b[?25hCollecting python-editor>=0.3\n",
            "  Downloading https://files.pythonhosted.org/packages/c6/d3/201fc3abe391bbae6606e6f1d598c15d367033332bd54352b12f35513717/python_editor-1.0.4-py3-none-any.whl\n",
            "Requirement already satisfied: prometheus_client in /usr/local/lib/python3.7/dist-packages (from prometheus-flask-exporter->mlflow<=1.13.1->farm==0.8.0->farm-haystack==0.9.0) (0.11.0)\n",
            "Collecting msrest>=0.6.18\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e8/cc/6c96bfb3d3cf4c3bdedfa6b46503223f4c2a4fa388377697e0f8082a4fed/msrest-0.6.21-py2.py3-none-any.whl (85kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 14.2MB/s \n",
            "\u001b[?25hCollecting cryptography>=2.1.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b2/26/7af637e6a7e87258b963f1731c5982fb31cd507f0d90d91836e446955d02/cryptography-3.4.7-cp36-abi3-manylinux2014_x86_64.whl (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 43.4MB/s \n",
            "\u001b[?25hCollecting azure-core<2.0.0,>=1.10.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/0a/837c3071ed24adba0e6733991b967336069bd49f1abf018ceae38a8ea759/azure_core-1.16.0-py2.py3-none-any.whl (163kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 59.0MB/s \n",
            "\u001b[?25hCollecting gitdb<5,>=4.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/e8/f414d1a4f0bbc668ed441f74f44c116d9816833a48bf81d22b697090dba8/gitdb-4.0.7-py3-none-any.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 10.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.7/dist-packages (from databricks-cli>=0.8.7->mlflow<=1.13.1->farm==0.8.0->farm-haystack==0.9.0) (0.8.9)\n",
            "Collecting websocket-client>=0.32.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/5f/3c211d168b2e9f9342cfb53bcfc26aab0eac63b998015e7af7bcae66119d/websocket_client-1.1.0-py2.py3-none-any.whl (68kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 10.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests-oauthlib>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from msrest>=0.6.18->azure-storage-blob>=12.0.0->mlflow<=1.13.1->farm==0.8.0->farm-haystack==0.9.0) (1.3.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=2.1.4->azure-storage-blob>=12.0.0->mlflow<=1.13.1->farm==0.8.0->farm-haystack==0.9.0) (1.14.5)\n",
            "Collecting smmap<5,>=3.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/68/ee/d540eb5e5996eb81c26ceffac6ee49041d473bc5125f2aa995cf51ec1cf1/smmap-4.0.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.5.0->msrest>=0.6.18->azure-storage-blob>=12.0.0->mlflow<=1.13.1->farm==0.8.0->farm-haystack==0.9.0) (3.1.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=2.1.4->azure-storage-blob>=12.0.0->mlflow<=1.13.1->farm==0.8.0->farm-haystack==0.9.0) (2.20)\n",
            "Building wheels for collected packages: farm-haystack, langdetect, python-multipart, python-docx, tika, seqeval, alembic, prometheus-flask-exporter, databricks-cli\n",
            "  Building wheel for farm-haystack (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for farm-haystack: filename=farm_haystack-0.9.0-cp37-none-any.whl size=184135 sha256=96df37ad02fdfa890c839dd40dc92ed2398b06ce7349b7baaa51e7fb931d2ec3\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-1k58a21e/wheels/ab/41/a4/4fbf362de283352078ecb6705c08b6525347aaea2eead2a60c\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-cp37-none-any.whl size=993242 sha256=8d9007d39bcbe79ad5bad81ce0a0701ca2adae3240de29ea95a1909361b85c35\n",
            "  Stored in directory: /root/.cache/pip/wheels/7e/18/13/038c34057808931c7ddc6c92d3aa015cf1a498df5a70268996\n",
            "  Building wheel for python-multipart (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-multipart: filename=python_multipart-0.0.5-cp37-none-any.whl size=31677 sha256=ac4ed1be69ef1160827d31d4d5f0f1c527a1b81a281a71e833e91867e2d8c0af\n",
            "  Stored in directory: /root/.cache/pip/wheels/f0/e6/66/14a866a3cbd6a0cabfbef91f7edf40aa03595ef6c88d6d1be4\n",
            "  Building wheel for python-docx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-docx: filename=python_docx-0.8.11-cp37-none-any.whl size=184508 sha256=bd82ad5b6f101fa2c594dee52fd93c9ab02906315bfa6829248b5132b32d6b26\n",
            "  Stored in directory: /root/.cache/pip/wheels/a6/90/f1/a7cb70b38633ae04e7fb963b1c70f63fd6fc01c075b8230adc\n",
            "  Building wheel for tika (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tika: filename=tika-1.24-cp37-none-any.whl size=32894 sha256=89ec7b74e2f5a7e2679991ed6d64144826f62029d6ba6bea32d0466c470c5dcc\n",
            "  Stored in directory: /root/.cache/pip/wheels/73/9c/f5/0b1b738442fc2a2862bef95b908b374f8e80215550fb2a8975\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-cp37-none-any.whl size=16184 sha256=a7a6b2865df489a796f695353595c9cdc03a3e3f2736b7facacc3cb853184026\n",
            "  Stored in directory: /root/.cache/pip/wheels/52/df/1b/45d75646c37428f7e626214704a0e35bd3cfc32eda37e59e5f\n",
            "  Building wheel for alembic (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for alembic: filename=alembic-1.4.1-py2.py3-none-any.whl size=158170 sha256=bbc3c6d80f7da492aca222fb5f9367b634efd9e0ffc53fbbe37b639efa4cad93\n",
            "  Stored in directory: /root/.cache/pip/wheels/84/07/f7/12f7370ca47a66030c2edeedcc23dec26ea0ac22dcb4c4a0f3\n",
            "  Building wheel for prometheus-flask-exporter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for prometheus-flask-exporter: filename=prometheus_flask_exporter-0.18.2-cp37-none-any.whl size=17415 sha256=91b86c839fe9610551d79dfe5df36f2b684a598c70b622d218d8784af014c89a\n",
            "  Stored in directory: /root/.cache/pip/wheels/c0/e2/9c/4f3ee23964802940f81a8b476d0b9be6fb6348cb12df2e2226\n",
            "  Building wheel for databricks-cli (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for databricks-cli: filename=databricks_cli-0.14.3-cp37-none-any.whl size=100560 sha256=86ea17692c19260fc92207ad1f59a7a2a422cedeafc2d65cb6d5e1539e786d82\n",
            "  Stored in directory: /root/.cache/pip/wheels/5b/24/f3/34d8e3964dac4ba849d844273c49a679111b00d5799ebb934a\n",
            "Successfully built farm-haystack langdetect python-multipart python-docx tika seqeval alembic prometheus-flask-exporter databricks-cli\n",
            "\u001b[31mERROR: torchvision 0.10.0+cu102 has requirement torch==1.9.0, but you'll have torch 1.8.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: torchtext 0.10.0 has requirement torch==1.9.0, but you'll have torch 1.8.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: pytest 3.6.4 has requirement pluggy<0.8,>=0.5, but you'll have pluggy 0.13.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: botocore 1.20.109 has requirement urllib3<1.27,>=1.25.4, but you'll have urllib3 1.24.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: weaviate-client 2.5.0 has requirement tqdm>=4.59.0, but you'll have tqdm 4.41.1 which is incompatible.\u001b[0m\n",
            "Installing collected packages: flask-cors, jmespath, botocore, s3transfer, boto3, Werkzeug, Mako, python-editor, alembic, prometheus-flask-exporter, isodate, msrest, cryptography, azure-core, azure-storage-blob, gunicorn, smmap, gitdb, gitpython, databricks-cli, websocket-client, docker, querystring-parser, mlflow, aniso8601, flask-restplus, seqeval, torch, sentencepiece, tokenizers, sacremoses, huggingface-hub, transformers, dotmap, farm, starlette, pydantic, fastapi, h11, asgiref, uvicorn, elasticsearch, elastic-apm, distlib, virtualenv, pluggy, tox, langdetect, python-multipart, python-docx, sqlalchemy-utils, faiss-cpu, tika, httptools, ujson, pymilvus, rdflib, SPARQLWrapper, mmh3, validators, weaviate-client, psycopg2-binary, uvloop, farm-haystack\n",
            "  Found existing installation: Werkzeug 1.0.1\n",
            "    Uninstalling Werkzeug-1.0.1:\n",
            "      Successfully uninstalled Werkzeug-1.0.1\n",
            "  Found existing installation: torch 1.9.0+cu102\n",
            "    Uninstalling torch-1.9.0+cu102:\n",
            "      Successfully uninstalled torch-1.9.0+cu102\n",
            "  Found existing installation: pluggy 0.7.1\n",
            "    Uninstalling pluggy-0.7.1:\n",
            "      Successfully uninstalled pluggy-0.7.1\n",
            "Successfully installed Mako-1.1.4 SPARQLWrapper-1.8.5 Werkzeug-0.16.1 alembic-1.4.1 aniso8601-9.0.1 asgiref-3.4.1 azure-core-1.16.0 azure-storage-blob-12.8.1 boto3-1.17.109 botocore-1.20.109 cryptography-3.4.7 databricks-cli-0.14.3 distlib-0.3.2 docker-5.0.0 dotmap-1.3.23 elastic-apm-6.3.2 elasticsearch-7.10.0 faiss-cpu-1.7.1.post2 farm-0.8.0 farm-haystack-0.9.0 fastapi-0.66.0 flask-cors-3.0.10 flask-restplus-0.13.0 gitdb-4.0.7 gitpython-3.1.18 gunicorn-20.1.0 h11-0.12.0 httptools-0.2.0 huggingface-hub-0.0.8 isodate-0.6.0 jmespath-0.10.0 langdetect-1.0.9 mlflow-1.13.1 mmh3-3.0.0 msrest-0.6.21 pluggy-0.13.1 prometheus-flask-exporter-0.18.2 psycopg2-binary-2.9.1 pydantic-1.8.2 pymilvus-1.1.2 python-docx-0.8.11 python-editor-1.0.4 python-multipart-0.0.5 querystring-parser-1.2.4 rdflib-5.0.0 s3transfer-0.4.2 sacremoses-0.0.45 sentencepiece-0.1.96 seqeval-1.2.2 smmap-4.0.0 sqlalchemy-utils-0.37.8 starlette-0.14.2 tika-1.24 tokenizers-0.10.3 torch-1.8.1 tox-3.23.1 transformers-4.6.1 ujson-4.0.2 uvicorn-0.14.0 uvloop-0.14.0 validators-0.18.2 virtualenv-20.4.7 weaviate-client-2.5.0 websocket-client-1.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5x3791kY7CUI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "038205e1-19bc-4471-ac44-4d1a356c4295"
      },
      "source": [
        "from haystack.preprocessor.cleaning import clean_wiki_text\n",
        "from haystack.preprocessor.utils import convert_files_to_dicts, fetch_archive_from_http\n",
        "from haystack.reader.farm import FARMReader\n",
        "from haystack.reader.transformers import TransformersReader\n",
        "from haystack.utils import print_answers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "07/11/2021 19:45:05 - INFO - faiss.loader -   Loading faiss with AVX2 support.\n",
            "07/11/2021 19:45:05 - INFO - faiss.loader -   Could not load library with AVX2 support due to:\n",
            "ModuleNotFoundError(\"No module named 'faiss.swigfaiss_avx2'\")\n",
            "07/11/2021 19:45:05 - INFO - faiss.loader -   Loading faiss.\n",
            "07/11/2021 19:45:05 - INFO - faiss.loader -   Successfully loaded faiss.\n",
            "07/11/2021 19:45:05 - INFO - farm.modeling.prediction_head -   Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qykeg9Hs7CUJ"
      },
      "source": [
        "## Document Store\n",
        "\n",
        "Haystack finds answers to queries within the documents stored in a `DocumentStore`. The current implementations of `DocumentStore` include `ElasticsearchDocumentStore`, `FAISSDocumentStore`,  `SQLDocumentStore`, and `InMemoryDocumentStore`.\n",
        "\n",
        "**Here:** We recommended Elasticsearch as it comes preloaded with features like [full-text queries](https://www.elastic.co/guide/en/elasticsearch/reference/current/full-text-queries.html), [BM25 retrieval](https://www.elastic.co/elasticon/conf/2016/sf/improved-text-scoring-with-bm25), and [vector storage for text embeddings](https://www.elastic.co/guide/en/elasticsearch/reference/7.6/dense-vector.html).\n",
        "\n",
        "**Alternatives:** If you are unable to setup an Elasticsearch instance, then follow the [Tutorial 3](https://github.com/deepset-ai/haystack/blob/master/tutorials/Tutorial3_Basic_QA_Pipeline_without_Elasticsearch.ipynb) for using SQL/InMemory document stores.\n",
        "\n",
        "**Hint**: This tutorial creates a new document store instance with Wikipedia articles on Game of Thrones. However, you can configure Haystack to work with your existing document stores.\n",
        "\n",
        "### Start an Elasticsearch server\n",
        "You can start Elasticsearch on your local machine instance using Docker. If Docker is not readily available in your environment (eg., in Colab notebooks), then you can manually download and execute Elasticsearch from source."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j73LMp1k7CUJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8215612b-57be-4aae-9506-0d6f8aec1b66"
      },
      "source": [
        "# Recommended: Start Elasticsearch using Docker via the Haystack utility function\n",
        "from haystack.utils import launch_es\n",
        "\n",
        "launch_es()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "07/11/2021 19:07:56 - INFO - haystack.utils -   Starting Elasticsearch ...\n",
            "07/11/2021 19:07:56 - WARNING - haystack.utils -   Tried to start Elasticsearch through Docker but this failed. It is likely that there is already an existing Elasticsearch instance running. \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7McET0r77CUK"
      },
      "source": [
        "# In Colab / No Docker environments: Start Elasticsearch from source\n",
        "! wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.9.2-linux-x86_64.tar.gz -q\n",
        "! tar -xzf elasticsearch-7.9.2-linux-x86_64.tar.gz\n",
        "! chown -R daemon:daemon elasticsearch-7.9.2\n",
        "\n",
        "import os\n",
        "from subprocess import Popen, PIPE, STDOUT\n",
        "es_server = Popen(['elasticsearch-7.9.2/bin/elasticsearch'],\n",
        "                   stdout=PIPE, stderr=STDOUT,\n",
        "                   preexec_fn=lambda: os.setuid(1)  # as daemon\n",
        "                  )\n",
        "# wait until ES has started\n",
        "! sleep 30"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "w6fgqYSf7CUK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2652945b-1267-45b8-de6b-382324d73415"
      },
      "source": [
        "# Connect to Elasticsearch\n",
        "\n",
        "from haystack.document_store.elasticsearch import ElasticsearchDocumentStore\n",
        "document_store = ElasticsearchDocumentStore(host=\"localhost\", username=\"\", password=\"\", index=\"document\")\n",
        "document_store.delete_all_documents\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "07/11/2021 19:48:34 - INFO - elasticsearch -   HEAD http://localhost:9200/ [status:200 request:0.078s]\n",
            "07/11/2021 19:48:34 - INFO - elasticsearch -   PUT http://localhost:9200/document [status:200 request:0.295s]\n",
            "07/11/2021 19:48:34 - INFO - elasticsearch -   PUT http://localhost:9200/label [status:200 request:0.178s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method ElasticsearchDocumentStore.delete_all_documents of <haystack.document_store.elasticsearch.ElasticsearchDocumentStore object at 0x7f2c32a63790>>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "I8iaJiYD7CUK"
      },
      "source": [
        "## Preprocessing of documents\n",
        "\n",
        "Haystack provides a customizable pipeline for:\n",
        " - converting files into texts\n",
        " - cleaning texts\n",
        " - splitting texts\n",
        " - writing them to a Document Store\n",
        "\n",
        "In this tutorial, we download Wikipedia articles about Game of Thrones, apply a basic cleaning function, and index them in Elasticsearch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "FB7MAM-s7CUK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "b9cc77db-966a-4ae5-b7a2-ec91b1d4ba4a"
      },
      "source": [
        "# Let's first fetch some documents that we want to query\n",
        "# Here: 517 Wikipedia articles for Game of Thrones\n",
        "docs = \"data/crypto\"\n",
        "\n",
        "#fetch_archive_from_http(url=s3_url, output_dir=doc_dir)\n",
        "\n",
        "# Convert files to dicts\n",
        "# You can optionally supply a cleaning function that is applied to each doc (e.g. to remove footers)\n",
        "# It must take a str as input, and return a str.\n",
        "dicts = convert_files_to_dicts(dir_path=docs, clean_func=clean_wiki_text, split_paragraphs=True)\n",
        "#print(dicts[0])\n",
        "# We now have a list of dictionaries that we can write to our document store.\n",
        "# If your texts come from a different source (e.g. a DB), you can of course skip convert_files_to_dicts() and create the dictionaries yourself.\n",
        "# The default format here is:\n",
        "# {\n",
        "#    'text': \"<DOCUMENT_TEXT_HERE>\",\n",
        "#    'meta': {'name': \"<DOCUMENT_NAME_HERE>\", ...}\n",
        "#}\n",
        "# (Optionally: you can also add more key-value-pairs here, that will be indexed as fields in Elasticsearch and\n",
        "# can be accessed later for filtering or shown in the responses of the Finder)\n",
        "\n",
        "# Let's have a look at the first 3 entries:\n",
        "#####print(dicts[:3])\n",
        "\n",
        "# Now, let's write the dicts containing documents to our DB.\n",
        "document_store.write_documents(dicts)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-6ccd6e8a6a69>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# You can optionally supply a cleaning function that is applied to each doc (e.g. to remove footers)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# It must take a str as input, and return a str.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mdicts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_files_to_dicts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclean_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclean_wiki_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit_paragraphs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;31m#print(dicts[0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# We now have a list of dictionaries that we can write to our document store.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'convert_files_to_dicts' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WK2Ccp5L7CUL"
      },
      "source": [
        "## Initalize Retriever, Reader,  & Finder\n",
        "\n",
        "### Retriever\n",
        "\n",
        "Retrievers help narrowing down the scope for the Reader to smaller units of text where a given question could be answered.\n",
        "They use some simple but fast algorithm.\n",
        "\n",
        "**Here:** We use Elasticsearch's default BM25 algorithm\n",
        "\n",
        "**Alternatives:**\n",
        "\n",
        "- Customize the `ElasticsearchRetriever`with custom queries (e.g. boosting) and filters\n",
        "- Use `TfidfRetriever` in combination with a SQL or InMemory Document store for simple prototyping and debugging\n",
        "- Use `EmbeddingRetriever` to find candidate documents based on the similarity of embeddings (e.g. created via Sentence-BERT)\n",
        "- Use `DensePassageRetriever` to use different embedding models for passage and query (see Tutorial 6)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAod1xuu7CUL"
      },
      "source": [
        "from haystack.retriever.sparse import ElasticsearchRetriever\n",
        "retriever = ElasticsearchRetriever(document_store=document_store)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%%\n"
        },
        "id": "_3QcFWb77CUL"
      },
      "source": [
        "# Alternative: An in-memory TfidfRetriever based on Pandas dataframes for building quick-prototypes with SQLite document store.\n",
        "\n",
        "# from haystack.retriever.sparse import TfidfRetriever\n",
        "# retriever = TfidfRetriever(document_store=document_store)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CdBmhoQb7CUM"
      },
      "source": [
        "### Reader\n",
        "\n",
        "A Reader scans the texts returned by retrievers in detail and extracts the k best answers. They are based\n",
        "on powerful, but slower deep learning models.\n",
        "\n",
        "Haystack currently supports Readers based on the frameworks FARM and Transformers.\n",
        "With both you can either load a local model or one from Hugging Face's model hub (https://huggingface.co/models).\n",
        "\n",
        "**Here:** a medium sized RoBERTa QA model using a Reader based on FARM (https://huggingface.co/deepset/roberta-base-squad2)\n",
        "\n",
        "**Alternatives (Reader):** TransformersReader (leveraging the `pipeline` of the Transformers package)\n",
        "\n",
        "**Alternatives (Models):** e.g. \"distilbert-base-uncased-distilled-squad\" (fast) or \"deepset/bert-large-uncased-whole-word-masking-squad2\" (good accuracy)\n",
        "\n",
        "**Hint:** You can adjust the model to return \"no answer possible\" with the no_ans_boost. Higher values mean the model prefers \"no answer possible\"\n",
        "\n",
        "#### FARMReader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false
        },
        "id": "U3s2gM2N7CUM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "d246f372-7c30-437e-de29-8ee191074b72"
      },
      "source": [
        "# Load a  local model or any of the QA models on\n",
        "# Hugging Face's model hub (https://huggingface.co/models)\n",
        "\n",
        "reader = FARMReader(model_name_or_path=\"deepset/roberta-base-squad2\", use_gpu=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-21be5d392314>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Hugging Face's model hub (https://huggingface.co/models)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFARMReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name_or_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"deepset/roberta-base-squad2\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_gpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'FARMReader' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0DF63ja7CUM"
      },
      "source": [
        "#### TransformersReader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGRUwqzN7CUM"
      },
      "source": [
        "# Alternative:\n",
        "# reader = TransformersReader(model_name_or_path=\"distilbert-base-uncased-distilled-squad\", tokenizer=\"distilbert-base-uncased\", use_gpu=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mnXcr2sY7CUM"
      },
      "source": [
        "### Pipeline\n",
        "\n",
        "With a Haystack `Pipeline` you can stick together your building blocks to a search pipeline.\n",
        "Under the hood, `Pipelines` are Directed Acyclic Graphs (DAGs) that you can easily customize for your own use cases.\n",
        "To speed things up, Haystack also comes with a few predefined Pipelines. One of them is the `ExtractiveQAPipeline` that combines a retriever and a reader to answer our questions.\n",
        "You can learn more about `Pipelines` in the [docs](https://haystack.deepset.ai/docs/latest/pipelinesmd)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false
        },
        "id": "AeKvKSnx7CUN"
      },
      "source": [
        "from haystack.pipeline import ExtractiveQAPipeline\n",
        "pipe = ExtractiveQAPipeline(reader, retriever)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q8qd-tgy7CUN"
      },
      "source": [
        "## Voilà! Ask a question!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false
        },
        "id": "Pq-20PFg7CUN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3933010d-18ca-4421-88ff-637faec91606"
      },
      "source": [
        "# You can configure how many candidates the reader and retriever shall return\n",
        "# The higher top_k_retriever, the better (but also the slower) your answers. \n",
        "prediction = pipe.run(query=\"why to use bitcoin\", top_k_retriever=10, top_k_reader=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "07/11/2021 19:53:53 - INFO - elasticsearch -   POST http://localhost:9200/document/_search [status:200 request:0.040s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.14 Batches/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxOOSFx37CUN"
      },
      "source": [
        "# prediction = pipe.run(query=\"Who created the Dothraki vocabulary?\", top_k_reader=5)\n",
        "# prediction = pipe.run(query=\"Who is the sister of Sansa?\", top_k_reader=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%%\n"
        },
        "id": "4pghpnRY7CUN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "127f948b-d5ab-4fce-cd89-d03e3b56d81a"
      },
      "source": [
        "print_answers(prediction, details=\"minimal\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[   {   'answer': 'it so far exists outside the institutional banking system '\n",
            "                  'and the control of governments',\n",
            "        'context': 'ch-savvy libertarians, because it so far exists outside '\n",
            "                   'the institutional banking system and the control of '\n",
            "                   'governments. However, researchers looking '},\n",
            "    {   'answer': 'function as pecuniary resources and are used as a medium of '\n",
            "                  'exchange and a means of payment',\n",
            "        'context': ' bank account. They therefore function as pecuniary '\n",
            "                   'resources and are used as a medium of exchange and a means '\n",
            "                   'of payment.\" The U.S. Treasury categori'},\n",
            "    {   'answer': 'payments reduces the sensitivity of the exchange rate to '\n",
            "                  'the beliefs of speculators about the future value of a '\n",
            "                  'virtual currency',\n",
            "        'context': ' usage for payments reduces the sensitivity of the '\n",
            "                   'exchange rate to the beliefs of speculators about the '\n",
            "                   'future value of a virtual currency. According'},\n",
            "    {   'answer': 'circumventing U.S. sanctions and accessing international '\n",
            "                  'financing',\n",
            "        'context': \"'strong bolívar') currency, as a means of circumventing \"\n",
            "                   'U.S. sanctions and accessing international financing. On '\n",
            "                   '20 August 2018, the bolívar soberano '},\n",
            "    {   'answer': 'to cover unexpected legal and development costs',\n",
            "        'context': 'before launch. The developers claimed that this was to '\n",
            "                   'cover unexpected legal and development costs.\\n'\n",
            "                   \"On January 6, 2014, Kanye West's lawyers sent the\"}]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "1d_mMlMb7CUO"
      },
      "source": [
        "## About us\n",
        "\n",
        "This [Haystack](https://github.com/deepset-ai/haystack/) notebook was made with love by [deepset](https://deepset.ai/) in Berlin, Germany\n",
        "\n",
        "We bring NLP to the industry via open source!  \n",
        "Our focus: Industry specific language models & large scale QA systems.  \n",
        "  \n",
        "Some of our other work: \n",
        "- [German BERT](https://deepset.ai/german-bert)\n",
        "- [GermanQuAD and GermanDPR](https://deepset.ai/germanquad)\n",
        "- [FARM](https://github.com/deepset-ai/FARM)\n",
        "\n",
        "Get in touch:\n",
        "[Twitter](https://twitter.com/deepset_ai) | [LinkedIn](https://www.linkedin.com/company/deepset-ai/) | [Slack](https://haystack.deepset.ai/community/join) | [GitHub Discussions](https://github.com/deepset-ai/haystack/discussions) | [Website](https://deepset.ai)\n",
        "\n",
        "By the way: [we're hiring!](https://apply.workable.com/deepset/) \n"
      ]
    }
  ]
}